{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_MNIST",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aihoque2/handwritten_digits/blob/master/PyTorch_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlcRYlolhht4"
      },
      "source": [
        "Here, I create a neural network for the MNIST dataset; because, do you really work on AI if you don't have an a neural network for the MNIST dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQO1iNH2hT59"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "import torch.optim as optim\n",
        "\n",
        "##import our mnist\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "SEED = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTvefiEclabl"
      },
      "source": [
        "let's see if we have CUDA. I'm using a free colab notebook with a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoohSjtQlfPx"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY7foJkBme5_"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHY8xVCHoFGp"
      },
      "source": [
        "let's load the MNIST dataset. we do it like this:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLC7wCunc9X"
      },
      "source": [
        "train = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
        "  transforms.ToTensor() #ToTensor for the MinMax normalization\n",
        "]))\n",
        "test = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
        "      transforms.ToTensor() #ToTensor for the MinMax normalization\n",
        "]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQC7kiPq5Hj"
      },
      "source": [
        "we gon' form the dataloader for training and testing, and then we gon' make the image tensor of all 600000 images in the MNIST traning dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdpAXyboq4qB"
      },
      "source": [
        "dataloader_kwargs = dict(shuffle=True, batch_size=256, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64) \n",
        "\n",
        "train_loader = dataloader.DataLoader(train, **dataloader_kwargs)\n",
        "test_loader = dataloader.DataLoader(test, **dataloader_kwargs)\n",
        "\n",
        "train_data = train.train_data\n",
        "test_data = test.test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1OYqqusY4-t"
      },
      "source": [
        "let's look at the train data tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvvs34nwY_EL"
      },
      "source": [
        "train_data.shape\n",
        "\n",
        "print('[Train]')\n",
        "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
        "print(' - Tensor Shape:', train.train_data.size())\n",
        "print(' - min:', torch.min(train_data))\n",
        "print(' - max:', torch.max(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lfPi597ZvlX"
      },
      "source": [
        "let's go and view an image with our image viewer function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J201nOzNZ03X"
      },
      "source": [
        "def show_images(batch, labels):\n",
        "  plt.figure(figsize=(10, 9))\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "  for n in range(30):\n",
        "    plt.subplot(6,5, n+1) #create our subplot 6x5 \n",
        "    plt.imshow(batch[n].view(batch[n].shape[1], batch[n].shape[2]), cmap=\"gray\")\n",
        "    plt.title(str(labels[n].item()))\n",
        "    plt.axis(\"off\")\n",
        "    _= plt.suptitle(\"MNIST Dataset \")\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "my_batch = torch.narrow(images, 0, 128, 32)\n",
        "batch_labels = torch.narrow(labels,0, 128, 32)\n",
        "#print(\"images.shape\")\n",
        "#print(images.shape)\n",
        "\n",
        "#print(\"my_batch shape\")\n",
        "#print(my_batch.shape)\n",
        "\n",
        "show_images(my_batch, batch_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbvxYoi7O4L"
      },
      "source": [
        "here are the labels too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haq2Ko_87TeG"
      },
      "source": [
        "print(batch_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FWyOZnHnaqt"
      },
      "source": [
        "# Defining our model, our train, and test functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R1hqK3NnheK"
      },
      "source": [
        "so here's the model I created. it's a convolutional net I made in my AI course at UIUC, and I want to test it on the MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoF-VhbKngmr"
      },
      "source": [
        "class convNet(torch.nn.Module):\n",
        "    def __init__(self, lrate, in_size, out_size, momentum):\n",
        "      super(convNet, self).__init__()\n",
        "\n",
        "      #you need the layers, the loss function, and the optimizer\n",
        "\n",
        "      self.conv1 = nn.Conv2d(1, 10, 5)\n",
        "      self.hidden1 = nn.Linear(10*12*12, 300) #put the pooled features through a hidden layer\n",
        "      self.output = nn.Linear(300, out_size) #this layer classifies for us\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "      self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "\n",
        "      self.optimizer = optim.SGD(self.parameters(), lr=lrate, momentum=momentum)\n",
        "      self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return self.parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #implement forward propogation\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 10*12*12)\n",
        "        x = self.relu(self.hidden1(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "    def step(self, x, y):\n",
        "        #perform a gradient descent step\n",
        "\n",
        "        #ALWAYS zero the gradient before you step\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        outputs = self.forward(x)\n",
        "\n",
        "        #get the loss and backpropagate it\n",
        "        loss = self.loss_fn(outputs, y)\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "        L = loss.item()\n",
        "        return L\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4DRmDUbxgFv"
      },
      "source": [
        "Now that we have the model defined, we will create the train function for the model to use. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEIFdLF5xxSj"
      },
      "source": [
        "def train(model, train_loader, n_epochs=5):\n",
        "  losses = []\n",
        "  for t in range(n_epochs):\n",
        "    curr_loss = 0.0\n",
        "    for i, data_batch in enumerate(train_loader):\n",
        "      data, labels = data_batch\n",
        "      curr_loss += model.step(data, labels)\n",
        "\n",
        "    print(\"loss for epoch \", t+1)\n",
        "    print(curr_loss)\n",
        "    losses.append(curr_loss)\n",
        "    \n",
        "  return losses\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbVo48XXkbvY"
      },
      "source": [
        "Create the test function too for our accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmvWGj-f6wB_"
      },
      "source": [
        "def test(model, test_loader, n):\r\n",
        "  num_correct = 0\r\n",
        "  for data_batch in test_loader:\r\n",
        "    input, labels = data_batch\r\n",
        "    output = model(input)\r\n",
        "    _, predicted = torch.max(output.data, 1)\r\n",
        "    num_correct += (predicted == labels).sum()\r\n",
        "  \r\n",
        "  return (num_correct/n)*100.0\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UywD_Gx7k_XX"
      },
      "source": [
        "# Fitting our function\r\n",
        "\r\n",
        "now that we have our train, test, and model defined, let's train our model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QizJczgmk-yG"
      },
      "source": [
        "##Our parameters to pass in the model. 'learn_rate' and 'momentum' are some hyperparamters we tune\r\n",
        "learn_rate = 1e-3\r\n",
        "momentum = 0.9\r\n",
        "input_size = 784\r\n",
        "output_size = 10\r\n",
        "\r\n",
        "model = convNet(lrate=learn_rate, in_size=input_size, out_size=output_size, momentum=momentum) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5WNWdDSZSIf"
      },
      "source": [
        "let's train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0C5MN1GZRyh"
      },
      "source": [
        "losses = train(model=model, train_loader=train_loader, n_epochs=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj6o6xH602wx"
      },
      "source": [
        "Test out this model on some fresh data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtsZoX2i1IwQ"
      },
      "source": [
        "test_len = len(test_data)\r\n",
        "accuracy = test(model=model, test_loader=test_loader, n=test_len)\r\n",
        "print(accuracy.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVyClxeRTtMR"
      },
      "source": [
        "# Plot out the result\r\n",
        "\r\n",
        "here is our model making some predictions for us. let's use the train batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKtGSJbVnA1B"
      },
      "source": [
        "output = model.forward(my_batch)\r\n",
        "_, predictions = torch.max(output.data, 1)\r\n",
        "\r\n",
        "def show_prediction_results(batch, labels, predicted_labels):\r\n",
        "  plt.figure(figsize=(10, 10))\r\n",
        "  for n in range(30):\r\n",
        "    plt.subplot(6,5, n+1)\r\n",
        "    plt.subplots_adjust(hspace=0.5)\r\n",
        "    plt.imshow(batch[n].view(batch[n].shape[1], batch[n].shape[2]), cmap=\"gray\")\r\n",
        "    color = \"green\" if (predicted_labels[n].item() == labels[n].item()) else \"red\"\r\n",
        "    plt.title(\"number: \"+ str(predicted_labels[n].item()), color=color)\r\n",
        "    plt.axis(\"off\")\r\n",
        "    _= plt.suptitle(\"MNIST Predictions\")\r\n",
        "\r\n",
        "show_prediction_results(my_batch, batch_labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icu6MmjtPmZ"
      },
      "source": [
        "our model has given a 92% Accuracy on the MNIST dataset. It's amazing how such a simple network can give fascinating results"
      ]
    }
  ]
}
